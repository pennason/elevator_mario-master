# 设备连接端口
netty:
  cube:
    port: 27500
  car_roof:
    port: 27600
  car_roof_tls:
    port: 27610
  motor_port:
    port: 27700
  motor_port_tls:
    port: 27710
  front:
    port: 27800
  SingleBox:
    port: 27900
  SingleBox_tls:
    port: 27910
  escalator:
    port: 28000
  CarDoor:
    port: 28010

server:
  #  port: 8002
  port: 8080

# sa-token 配置
sa-token:
  # 配置 Sa-Token 单独使用的 Redis 连接
  alone-redis:
    database: 13  # 默认13
    host: 10.0.0.113
    port: 6379
    password: shmashine@666
    timeout: 5000

eureka:
  client:
    service-url:
      defaultZone: http://shmashine-eureka:8080/eureka/
  instance:
    instance-id: ${spring.cloud.client.ip-address}:${server.port}
    # 优先使用IP地址方式进行注册服务
    prefer-ip-address: true
#全局配置
# 请求连接的超时时间 默认的时间为 1 秒
ribbon:
  ConnectTimeout: 6000
  # 请求处理的超时时间
  ReadTimeout: 60000

mybatis-plus:
  mapper-locations: mapper/*.xml
  type-aliases-package: com.shmashine.UserClientApplets.entity
  configuration:
    map-underscore-to-camel-case: true    #开启驼峰功能
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl # 这个配置会将执行的sql打印出来，在开发或测试的时候可以用
  global-config:
    db-config:
      update-strategy: NOT_EMPTY # 更新时，只更新非空字段
      insert-strategy: NOT_EMPTY # 新增时，只新增非空字段
      id-type: auto   #id自增长
pagehelper:
  helper-dialect: mysql
  reasonable: true
  support-methods-arguments: true
  page-size-zero: true
  row-bound-with-count: false
  # params: count=countSql

# kafka topic 名称
kafka:
  topic:
    consumer:
      nettyTopic: dev_web_nezha
    producer:
      monitor: dev_oreo_monitor
      mergeMonitor: dev_cube_report_merge_monitor
      fault: dev_oreo_fault
      preFault: dev_oreo_preFault
      tr: dev_oreo_tr
      http: dev_netty_nezha
      event: dev_oreo_event
      detectedPeopleNums: dev_people_flow_statistics
      cubeMonitor: dev_cube_monitor
      cubeTr: dev_cube_tr
      cubeEvent: dev_cube_event
      cubeFault: dev_cube_fault
      cubeTrapped: dev_cube_trapped
      cubeOnlineOffline: dev_cube_online_offline

spring:
  application:
    name: shmashine-socket
  data:
    mongodb:
      host: 10.0.0.124
      port: 27017
      database: MX
      username: shmashine
      password: Shmashine@666
  profiles:
    active: dev
  redis:
    database: 1
    host: 124.220.207.150
    port: 6379
    password: MaiXin@666
    timeout: 5000
  datasource:
    oreo:
      type: com.alibaba.druid.pool.DruidDataSource
      driverClassName: com.mysql.cj.jdbc.Driver
      url: jdbc:mysql://10.0.0.113:3306/elevator_master?useSSL=false&useUnicode=true&characterEncoding=utf-8&allowMultiQueries=true&autoReconnect=true&failOverReadOnly=false&allowMultiQueries=true&serverTimezone=Asia/Shanghai
      username: root
      password: shmashine@666
      initialSize: 1
      minIdle: 3
      maxActive: 200
      # 配置获取连接等待超时的时间
      maxWait: 60000
      # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
      timeBetweenEvictionRunsMillis: 60000
      # 配置一个连接在池中最小生存的时间，单位是毫秒
      minEvictableIdleTimeMillis: 30000
      validationQuery: select 'x'
      testWhileIdle: true
      testOnBorrow: false
      testOnReturn: false
      # 打开PSCache，并且指定每个连接上PSCache的大小
      poolPreparedStatements: true
      maxPoolPreparedStatementPerConnectionSize: 20
      # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
      filters: stat,wall,slf4j
      # 通过connectProperties属性来打开mergeSql功能；慢SQL记录
      connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
      # 合并多个DruidDataSource的监控数据
      #useGlobalDataSourceStat: true
    nezha:
      type: com.alibaba.druid.pool.DruidDataSource
      driverClassName: com.mysql.cj.jdbc.Driver
      url: jdbc:mysql://10.0.0.113:3306/elevator_master?useSSL=false&useUnicode=true&characterEncoding=utf-8&allowMultiQueries=true&autoReconnect=true&failOverReadOnly=false&allowMultiQueries=true&serverTimezone=Asia/Shanghai
      username: root
      password: shmashine@666
      initialSize: 1
      minIdle: 3
      maxActive: 200
      # 配置获取连接等待超时的时间
      maxWait: 60000
      # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
      timeBetweenEvictionRunsMillis: 60000
      # 配置一个连接在池中最小生存的时间，单位是毫秒
      minEvictableIdleTimeMillis: 30000
      validationQuery: select 'x'
      testWhileIdle: true
      testOnBorrow: false
      testOnReturn: false
      # 打开PSCache，并且指定每个连接上PSCache的大小
      poolPreparedStatements: true
      maxPoolPreparedStatementPerConnectionSize: 20
      # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
      filters: stat,wall,slf4j
      # 通过connectProperties属性来打开mergeSql功能；慢SQL记录
      connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000

  kafka:
    producer:
      #      bootstrap-servers: kafka:9092
      bootstrap-servers: 47.122.9.58:9092
      retries: 0
      batch-size: 16384
      buffer-memory: 33554432
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      properties:
        security.protocol: SASL_PLAINTEXT
        sasl.mechanism: PLAIN
        sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username="shmashine" password="123456";
    consumer:
      #      bootstrap-servers: kafka:9092
      bootstrap-servers: 47.122.9.58:9092
      group-id: oreo-socket-group-testwu_test
      auto-offset-reset: latest
      enable-auto-commit: true
      auto-commit-interval: 100
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      properties:
        security.protocol: SASL_PLAINTEXT
        sasl.mechanism: PLAIN
        sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username="shmashine" password="123456";
  boot:
    admin:
      client:
        url: http://spring-boot-admin:8080 #配置admin-server地址
        username: shmashine
        password: shmashine
        instance:
          service-url: http://shmashine-socket:8080

# 故障屏蔽, 超过指定次数后不上报
fault-masking:
  # 每天故障上报次数大于5次-北向屏蔽
  north-fault-count-day: 5
  # 每小时故障上报次数大于3次-平台屏蔽
  platform-fault-count-hour: 3

# 监控信息
management:
  endpoints:
    web:
      exposure:
        #        include: "health,prometheus,httptrace"
        include: "*"
  endpoint:
    health:
      show-details: ALWAYS
      probes:
        enabled: true
      group:
        readiness:
          include: db
    prometheus:
      enabled: true
  metrics:
    tags:
      application: ${spring.application.name}
#logging:
#  file:
#    name: socket-server.log
