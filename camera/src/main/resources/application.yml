# kafka topic 名称
kafka:
  topic:
    hls: pro_fault_video_test
    socket: pro_web_nezha_test

server:
  #  port: 8005
  port: 8080

# sa-token 配置
sa-token:
  # 配置 Sa-Token 单独使用的 Redis 连接
  alone-redis:
    database: 13  # 默认13
    host: 10.0.0.113
    port: 6379
    password: shmashine@666
    timeout: 5000

eureka:
  client:
    service-url:
      defaultZone: http://shmashine-eureka:8080/eureka/
  instance:
    instance-id: ${spring.cloud.client.ip-address}:${server.port}
    # 优先使用IP地址方式进行注册服务
    prefer-ip-address: true

feign:
  hystrix:
    enabled: true
  client:
    config:
      default:
        read-timeout: 6000
        connect-timeout: 6000

spring:
  application:
    name: shmashine-camera
  main:
    allow-bean-definition-overriding: true
  jackson:
    time-zone: GMT+8
    date-format: yyyy-MM-dd HH:mm:ss
  profiles:
    active: dev
  redis:
    database: 2
    host: redis
    port: 6379
    password: shmashine@666
    timeout: 5000
  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    driverClassName: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://mysql.dev.shmashine.com:3306/elevator_master?useSSL=false&useUnicode=true&characterEncoding=utf-8&autoReconnect=true&failOverReadOnly=false&allowMultiQueries=true&serverTimezone=Asia/Shanghai
    username: root
    password: shmashine@666

    initialSize: 1
    minIdle: 3
    maxActive: 200
    # 配置获取连接等待超时的时间
    maxWait: 60000
    # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
    timeBetweenEvictionRunsMillis: 60000
    # 配置一个连接在池中最小生存的时间，单位是毫秒
    minEvictableIdleTimeMillis: 30000
    validationQuery: select 'x'
    testWhileIdle: true
    testOnBorrow: false
    testOnReturn: false
    # 打开PSCache，并且指定每个连接上PSCache的大小
    poolPreparedStatements: true
    maxPoolPreparedStatementPerConnectionSize: 20
    # 配置监控统计拦截的filters，去掉后监控界面sqla's无法统计，'wall'用于防火墙
    filters: stat,wall,slf4j
    # 通过connectProperties属性来打开mergeSql功能；慢SQL记录
    connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
    # 合并多个DruidDataSource的监控数据
    #useGlobalDataSourceStat: true
    #单个文件最大大小
  servlet:
    multipart:
      max-file-size: 600MB #单个文件上传大小
      max-request-size: 600MB #连续上传文件大小
      enabled: true
  kafka:
    producer:
      #      bootstrap-servers: kafka:9092
      bootstrap-servers: 47.122.9.58:9092
      retries: 0
      batch-size: 16384
      buffer-memory: 33554432
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      properties:
        security.protocol: SASL_PLAINTEXT
        sasl.mechanism: PLAIN
        sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username="shmashine" password="123456";
    consumer:
      #bootstrap-servers: kafka:9092
      bootstrap-servers: 47.122.9.58:9092
      group-id: shmashine-oreo-fault_test-wu
      auto-offset-reset: latest
      enable-auto-commit: true
      auto-commit-interval: 100
      max-poll-records: 50
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      properties:
        security.protocol: SASL_PLAINTEXT
        sasl.mechanism: PLAIN
        sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username="shmashine" password="123456";
  boot:
    admin:
      client:
        url: http://spring-boot-admin:8080
        username: shmashine
        password: shmashine
        instance:
          service-url: http://shmashine-camera:8080
  mvc:
    pathmatch:
      matching-strategy: ant_path_matcher
caching:
  specs:
    project:
      timeout: 30
      expireMode: 0
    dept:
      timeout: 30
      expireMode: 0

mybatis-plus:
  mapper-locations: mapper/*.xml
  type-aliases-package: com.shmashine.UserClientApplets.entity
  configuration:
    map-underscore-to-camel-case: true    #开启驼峰功能
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl # 这个配置会将执行的sql打印出来，在开发或测试的时候可以用
  global-config:
    db-config:
      update-strategy: NOT_EMPTY # 更新时，只更新非空字段
      insert-strategy: NOT_EMPTY # 新增时，只新增非空字段
      id-type: auto   #id自增长
pagehelper:
  helper-dialect: mysql
  reasonable: true
  support-methods-arguments: true
  page-size-zero: true
  row-bound-with-count: false
  # params: count=countSql

#logging:
#  config:
#    classpath: logback.xml
#    path: /var/log/${spring.application.name}
#  myFileName: ${spring.application.name}
#  # 分割文件设置 超过 100MB就进行分割，最大保留历史 90天
#  maxFileSize: 100MB
#  maxHistory: 90
#  level:
#    com.shmashine.camera: info
#  file:
#    name: camera-server.log
springdoc:
  swagger-ui:
    enabled: true
  api-docs:
    enabled: true

#logging:
#  config:
#    classpath: logback.xml
#    path: /var/log/${spring.application.name}
#  myFileName: ${spring.application.name}
#  # 分割文件设置 超过 100MB就进行分割，最大保留历史 90天
#  maxFileSize: 100MB
#  maxHistory: 90
#  level:
#    com.shmashine.camera: info
#  file:
#    name: camera-server.log
management:
  endpoints:
    web:
      exposure:
        #        include: "health,prometheus,httptrace"
        include: "*"
  endpoint:
    health:
      show-details: ALWAYS
      probes:
        enabled: true
      group:
        readiness:
          include: db
    prometheus:
      enabled: true
  metrics:
    tags:
      application: ${spring.application.name}
