server:
  session-timeout: 1800
  #  port: 8086
  port: 8080
  uri-encoding: utf-8
  tomcat:
    max-threads: 1000
    min-spare-threads: 30
  compression:
    enabled: true

# sa-token 配置
sa-token:
  # 配置 Sa-Token 单独使用的 Redis 连接
  alone-redis:
    database: 13  # 默认13
    host: 10.0.0.113
    port: 6379
    password: shmashine@666
    timeout: 5000

spring:
  application:
    name: sender-service
  profiles:
    active: dev
  main:
    allow-bean-definition-overriding: true

  thymeleaf:
    mode: LEGACYHTML5
    cache: false
  jackson:
    time-zone: GMT+8
    date-format: yyyy-MM-dd HH:mm:ss
  devtools:
    restart:
      enabled: true
  cache:
    jcache:
      config: classpath:ehcache.xml

  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    driverClassName: com.mysql.cj.jdbc.Driver
    #url: jdbc:mysql://124.220.207.150:3306/elevator_master?useSSL=false&useUnicode=true&characterEncoding=utf-8&autoReconnect=true&failOverReadOnly=false&allowMultiQueries=true&serverTimezone=Asia/Shanghai
    #username: admin
    #password: MaiXin@666
    url: jdbc:mysql://10.0.0.113:3306/elevator_master?SSL=false&sslMode=DISABLED&useUnicode=true&characterEncoding=utf-8&autoReconnect=true&failOverReadOnly=false&allowMultiQueries=true&serverTimezone=Asia/Shanghai
    username: root
    password: shmashine@666
    initialSize: 1
    minIdle: 3
    maxActive: 200
    # 配置获取连接等待超时的时间
    maxWait: 60000
    # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
    timeBetweenEvictionRunsMillis: 60000
    # 配置一个连接在池中最小生存的时间，单位是毫秒
    minEvictableIdleTimeMillis: 30000
    validationQuery: select 'x'
    testWhileIdle: true
    testOnBorrow: false
    testOnReturn: false
    # 打开PSCache，并且指定每个连接上PSCache的大小
    poolPreparedStatements: true
    maxPoolPreparedStatementPerConnectionSize: 20
    # 配置监控统计拦截的filters，去掉后监控界面sqla's无法统计，'wall'用于防火墙
    filters: stat,wall,slf4j
    # 通过connectProperties属性来打开mergeSql功能；慢SQL记录
    connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
    # 合并多个DruidDataSource的监控数据
    #useGlobalDataSourceStat: true
    #单个文件最大大小
  redis:
    database: 2
    host: redis.s113
    port: 6379
    password: shmashine@666
    timeout: 5000
  data:
    mongodb:
      host: 10.0.0.124
      port: 27017
      database: MX
      username: shmashine
      password: Shmashine@666

  kafka:
    producer:
      #      bootstrap-servers: kafka:9092
      bootstrap-servers: kafka.pro.shmashine.com:9092
      retries: 0
      batch-size: 16384
      buffer-memory: 33554432
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      properties:
        security.protocol: SASL_PLAINTEXT
        sasl.mechanism: PLAIN
        sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username="producer" password="secret20190219";
    consumer:
      #      bootstrap-servers: kafka:9092
      bootstrap-servers: kafka.pro.shmashine.com:9092
      group-id: pro-sender-yidian-juc-test
      auto-offset-reset: latest
      enable-auto-commit: true
      auto-commit-interval: 1000
      #max-poll-records: 800
      heartbeat-interval: 3000
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      properties:
        security.protocol: SASL_PLAINTEXT
        sasl.mechanism: PLAIN
        sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username="producer" password="secret20190219";
    listener:
      missing-topics-fatal: false

  boot:
    admin:
      client:
        url: http://spring-boot-admin:8080/
        username: shmashine
        password: shmashine
        instance:
          prefer-ip: true
          service-url: http://sender-service:8080

  servlet:
    multipart:
      max-file-size: 50MB
      max-request-size: 50MB

# 监控信息
management:
  endpoints:
    web:
      exposure:
        #        include: "health,prometheus,httptrace"
        include: "*"
  endpoint:
    health:
      show-details: ALWAYS
      probes:
        enabled: true
      group:
        readiness:
          include: db
    prometheus:
      enabled: true
  metrics:
    tags:
      application: ${spring.application.name}


#logging:
#  file:
#    name: sender-service.log
mybatis-plus:
  mapper-locations: mapper/*.xml
  type-aliases-package: com.shmashine.UserClientApplets.entity
  configuration:
    map-underscore-to-camel-case: true    #开启驼峰功能
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl # 这个配置会将执行的sql打印出来，在开发或测试的时候可以用
  global-config:
    db-config:
      update-strategy: NOT_EMPTY # 更新时，只更新非空字段
      insert-strategy: NOT_EMPTY # 新增时，只新增非空字段
      id-type: auto   #id自增长
pagehelper:
  helper-dialect: mysql
  reasonable: true
  support-methods-arguments: true
  page-size-zero: true
  row-bound-with-count: false
  # params: count=countSql


springdoc:
  api-docs:
    enabled: false

mdf:
  cache:
    enabled: true
    force-cache-provider: caffeine  # redis, caffeine, noop

# endpoint
endpoint:
  push-city-govern-domain: http://push.city.govern.shmashine.com